{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project_85426.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-wsqeVf7sXd"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRAeryw98Gzc"
      },
      "source": [
        "# creating  dataset in pandas:\n",
        "\n",
        "# first_formant values roughly calculated from Hillenbrand et al., 1994\n",
        "  # https://homepages.wmich.edu/~hillenbr/Papers/HillenbrandGettyClarkWheeler.pdf page 6:\n",
        "  # image also Figure 2 in Jacobs et al., 1994 (Adaptive Mixtures of Local Experts)\n",
        "  # Using 150 instances of each sound\n",
        "\n",
        "first_formant_a = np.random.randint(low=650,high=1150, size=150)\n",
        "first_formant_A = np.random.randint(low=530,high=880, size=150)\n",
        "first_formant_i = np.random.randint(low=300,high=500, size=150)\n",
        "first_formant_I = np.random.randint(low=375,high=550, size=150)\n",
        "\n",
        "# divided by 1000 in keeping with Local Experts paper:\n",
        "first_formant_a = first_formant_a/1000\n",
        "first_formant_A = first_formant_A/1000\n",
        "first_formant_i = first_formant_i/1000\n",
        "first_formant_I = first_formant_I/1000\n",
        "\n",
        "# second_formant values roughly calculated:\n",
        "second_formant_a = np.random.randint(low=1120,high=1800, size=150)\n",
        "second_formant_A = np.random.randint(low=1020,high=1610, size=150)\n",
        "second_formant_i = np.random.randint(low=2100,high=3400, size=150)\n",
        "second_formant_I = np.random.randint(low=1810,high=2790, size=150)\n",
        "\n",
        "\n",
        "second_formant_a = second_formant_a/1000\n",
        "second_formant_A = second_formant_A/1000\n",
        "second_formant_i = second_formant_i/1000\n",
        "second_formant_I = second_formant_I/1000"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "HIfo1MNvA7M6",
        "outputId": "7521bb13-cf00-4d52-d429-5bb4f9ceb704"
      },
      "source": [
        "# plot it\n",
        "plt.plot(first_formant_a, second_formant_a, 'bx')\n",
        "plt.plot(first_formant_A, second_formant_A, 'yx')\n",
        "plt.plot(first_formant_i, second_formant_i, 'gx')\n",
        "plt.plot(first_formant_I, second_formant_I, 'rx')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f21889e9b70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ahvL2ubYCMTp",
        "outputId": "8c8706a7-6544-4e39-b076-6c0cd026afd4"
      },
      "source": [
        "# # create data:\n",
        "\n",
        "first_formant = np.append(first_formant_a, first_formant_A)\n",
        "first_formant = np.append(first_formant, first_formant_i)\n",
        "first_formant = np.append(first_formant, first_formant_I)\n",
        "\n",
        "\n",
        "second_formant = np.append(second_formant_a, second_formant_A)\n",
        "second_formant = np.append(second_formant, second_formant_i)\n",
        "second_formant = np.append(second_formant, second_formant_I)\n",
        "\n",
        "\n",
        "# create target data:\n",
        "target_a = np.full((150,), \"a\")\n",
        "target_A = np.full((150,), \"A\")\n",
        "target_i = np.full((150,), \"i\")\n",
        "target_I = np.full((150,), \"I\")\n",
        "\n",
        "target = np.append(target_a, target_A)\n",
        "target = np.append(target, target_i)\n",
        "target = np.append(target, target_I)\n",
        "\n",
        "target = np.array(target)\n",
        "target\n",
        "\n",
        "\n",
        "# create data:\n",
        "formant_df = pd.DataFrame(data=[first_formant, second_formant, target])\n",
        "\n",
        "# sideways for some reason:\n",
        "formant_df = formant_df.T\n",
        "\n",
        "# name cols:\n",
        "formant_df.columns = ['first formant', 'second formant', 'target']\n",
        "formant_df\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first formant</th>\n",
              "      <th>second formant</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.842</td>\n",
              "      <td>1.293</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.793</td>\n",
              "      <td>1.137</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.923</td>\n",
              "      <td>1.534</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.823</td>\n",
              "      <td>1.746</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.939</td>\n",
              "      <td>1.359</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>0.456</td>\n",
              "      <td>2.77</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0.532</td>\n",
              "      <td>2.738</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>0.39</td>\n",
              "      <td>1.889</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>0.456</td>\n",
              "      <td>2.397</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>0.4</td>\n",
              "      <td>2.027</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    first formant second formant target\n",
              "0           0.842          1.293      a\n",
              "1           0.793          1.137      a\n",
              "2           0.923          1.534      a\n",
              "3           0.823          1.746      a\n",
              "4           0.939          1.359      a\n",
              "..            ...            ...    ...\n",
              "595         0.456           2.77      I\n",
              "596         0.532          2.738      I\n",
              "597          0.39          1.889      I\n",
              "598         0.456          2.397      I\n",
              "599           0.4          2.027      I\n",
              "\n",
              "[600 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WCDNJ5dDlmc",
        "outputId": "7116cf19-2c26-47bc-d870-d66f32e42301"
      },
      "source": [
        "# train-test split:\n",
        "\n",
        "# as they're in no particular order, can just split at last 20%:\n",
        "\n",
        "train_X, test_X = train_test_split(formant_df, test_size=0.2)\n",
        "\n",
        "# make target data:\n",
        "train_y = train_X['target']\n",
        "test_y = test_X['target']\n",
        "\n",
        "dummy_col_train = pd.get_dummies(train_X['target'])\n",
        "dummy_col_test = pd.get_dummies(test_X['target'])\n",
        "\n",
        "# one-hot encoding output data:\n",
        "new_train_y = np.array(dummy_col_train)\n",
        "new_test_y = np.array(dummy_col_test)\n",
        "\n",
        "# drop target column from x data:\n",
        "train_X = train_X.drop(columns=['target'])\n",
        "test_X = test_X.drop(columns=['target'])\n",
        "\n",
        "\n",
        "# convert both X and target data to numpy arrays:\n",
        "train_X = np.array(train_X)\n",
        "test_X = np.array(test_X)\n",
        "\n",
        "train_y = np.array(train_y)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "\n",
        "train_X = np.asarray(train_X).astype(np.float32)\n",
        "test_X = np.asarray(test_X).astype(np.float32)\n",
        "\n",
        "new_train_y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLby_m9rEZE1",
        "outputId": "68fe1f39-22e9-4d21-998b-9a0608dd2a24"
      },
      "source": [
        "\n",
        "# first control model described in the paper (one hidden layer 4 units):\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Dense(4, activation='relu', input_shape=(480,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "model.fit(\n",
        "  train_X,\n",
        "  new_train_y,\n",
        "  epochs=300,\n",
        "  batch_size=16,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "30/30 [==============================] - 0s 956us/step - loss: 1.3829 - accuracy: 0.2313\n",
            "Epoch 2/300\n",
            "30/30 [==============================] - 0s 892us/step - loss: 1.3710 - accuracy: 0.2313\n",
            "Epoch 3/300\n",
            "30/30 [==============================] - 0s 912us/step - loss: 1.3603 - accuracy: 0.2313\n",
            "Epoch 4/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.3516 - accuracy: 0.2313\n",
            "Epoch 5/300\n",
            "30/30 [==============================] - 0s 923us/step - loss: 1.3434 - accuracy: 0.2313\n",
            "Epoch 6/300\n",
            "30/30 [==============================] - 0s 915us/step - loss: 1.3359 - accuracy: 0.2313\n",
            "Epoch 7/300\n",
            "30/30 [==============================] - 0s 923us/step - loss: 1.3288 - accuracy: 0.2313\n",
            "Epoch 8/300\n",
            "30/30 [==============================] - 0s 961us/step - loss: 1.3220 - accuracy: 0.2313\n",
            "Epoch 9/300\n",
            "30/30 [==============================] - 0s 932us/step - loss: 1.3154 - accuracy: 0.2313\n",
            "Epoch 10/300\n",
            "30/30 [==============================] - 0s 932us/step - loss: 1.3083 - accuracy: 0.2313\n",
            "Epoch 11/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.3015 - accuracy: 0.2313\n",
            "Epoch 12/300\n",
            "30/30 [==============================] - 0s 956us/step - loss: 1.2941 - accuracy: 0.2313\n",
            "Epoch 13/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2870 - accuracy: 0.2333\n",
            "Epoch 14/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2793 - accuracy: 0.2375\n",
            "Epoch 15/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2714 - accuracy: 0.2438\n",
            "Epoch 16/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2635 - accuracy: 0.2458\n",
            "Epoch 17/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2553 - accuracy: 0.2146\n",
            "Epoch 18/300\n",
            "30/30 [==============================] - 0s 980us/step - loss: 1.2468 - accuracy: 0.2042\n",
            "Epoch 19/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2383 - accuracy: 0.2104\n",
            "Epoch 20/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2297 - accuracy: 0.2062\n",
            "Epoch 21/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2209 - accuracy: 0.2188\n",
            "Epoch 22/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2120 - accuracy: 0.2271\n",
            "Epoch 23/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2032 - accuracy: 0.2375\n",
            "Epoch 24/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1942 - accuracy: 0.2438\n",
            "Epoch 25/300\n",
            "30/30 [==============================] - 0s 962us/step - loss: 1.1855 - accuracy: 0.2562\n",
            "Epoch 26/300\n",
            "30/30 [==============================] - 0s 964us/step - loss: 1.1765 - accuracy: 0.2708\n",
            "Epoch 27/300\n",
            "30/30 [==============================] - 0s 984us/step - loss: 1.1677 - accuracy: 0.3104\n",
            "Epoch 28/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1590 - accuracy: 0.3604\n",
            "Epoch 29/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1504 - accuracy: 0.3917\n",
            "Epoch 30/300\n",
            "30/30 [==============================] - 0s 940us/step - loss: 1.1420 - accuracy: 0.4250\n",
            "Epoch 31/300\n",
            "30/30 [==============================] - 0s 949us/step - loss: 1.1336 - accuracy: 0.4354\n",
            "Epoch 32/300\n",
            "30/30 [==============================] - 0s 943us/step - loss: 1.1253 - accuracy: 0.4500\n",
            "Epoch 33/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1172 - accuracy: 0.4563\n",
            "Epoch 34/300\n",
            "30/30 [==============================] - 0s 977us/step - loss: 1.1092 - accuracy: 0.4625\n",
            "Epoch 35/300\n",
            "30/30 [==============================] - 0s 980us/step - loss: 1.1013 - accuracy: 0.4688\n",
            "Epoch 36/300\n",
            "30/30 [==============================] - 0s 988us/step - loss: 1.0937 - accuracy: 0.4729\n",
            "Epoch 37/300\n",
            "30/30 [==============================] - 0s 943us/step - loss: 1.0860 - accuracy: 0.4750\n",
            "Epoch 38/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0785 - accuracy: 0.4750\n",
            "Epoch 39/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0712 - accuracy: 0.4812\n",
            "Epoch 40/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0640 - accuracy: 0.4833\n",
            "Epoch 41/300\n",
            "30/30 [==============================] - 0s 912us/step - loss: 1.0572 - accuracy: 0.4896\n",
            "Epoch 42/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0502 - accuracy: 0.4896\n",
            "Epoch 43/300\n",
            "30/30 [==============================] - 0s 909us/step - loss: 1.0435 - accuracy: 0.4896\n",
            "Epoch 44/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0369 - accuracy: 0.4958\n",
            "Epoch 45/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0305 - accuracy: 0.4958\n",
            "Epoch 46/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0242 - accuracy: 0.4979\n",
            "Epoch 47/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0180 - accuracy: 0.5000\n",
            "Epoch 48/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0120 - accuracy: 0.4979\n",
            "Epoch 49/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0060 - accuracy: 0.5021\n",
            "Epoch 50/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0002 - accuracy: 0.5021\n",
            "Epoch 51/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9944 - accuracy: 0.5042\n",
            "Epoch 52/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9889 - accuracy: 0.5042\n",
            "Epoch 53/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9834 - accuracy: 0.5042\n",
            "Epoch 54/300\n",
            "30/30 [==============================] - 0s 927us/step - loss: 0.9779 - accuracy: 0.5042\n",
            "Epoch 55/300\n",
            "30/30 [==============================] - 0s 961us/step - loss: 0.9727 - accuracy: 0.5042\n",
            "Epoch 56/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9676 - accuracy: 0.5083\n",
            "Epoch 57/300\n",
            "30/30 [==============================] - 0s 917us/step - loss: 0.9625 - accuracy: 0.5083\n",
            "Epoch 58/300\n",
            "30/30 [==============================] - 0s 924us/step - loss: 0.9576 - accuracy: 0.5083\n",
            "Epoch 59/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9526 - accuracy: 0.5104\n",
            "Epoch 60/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9479 - accuracy: 0.5104\n",
            "Epoch 61/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9432 - accuracy: 0.5104\n",
            "Epoch 62/300\n",
            "30/30 [==============================] - 0s 917us/step - loss: 0.9388 - accuracy: 0.5104\n",
            "Epoch 63/300\n",
            "30/30 [==============================] - 0s 907us/step - loss: 0.9342 - accuracy: 0.5083\n",
            "Epoch 64/300\n",
            "30/30 [==============================] - 0s 925us/step - loss: 0.9300 - accuracy: 0.5104\n",
            "Epoch 65/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5104\n",
            "Epoch 66/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9214 - accuracy: 0.5104\n",
            "Epoch 67/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9173 - accuracy: 0.5125\n",
            "Epoch 68/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9133 - accuracy: 0.5125\n",
            "Epoch 69/300\n",
            "30/30 [==============================] - 0s 915us/step - loss: 0.9094 - accuracy: 0.5125\n",
            "Epoch 70/300\n",
            "30/30 [==============================] - 0s 973us/step - loss: 0.9055 - accuracy: 0.5104\n",
            "Epoch 71/300\n",
            "30/30 [==============================] - 0s 990us/step - loss: 0.9018 - accuracy: 0.5125\n",
            "Epoch 72/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8979 - accuracy: 0.5104\n",
            "Epoch 73/300\n",
            "30/30 [==============================] - 0s 952us/step - loss: 0.8943 - accuracy: 0.5125\n",
            "Epoch 74/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8907 - accuracy: 0.5104\n",
            "Epoch 75/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8872 - accuracy: 0.5104\n",
            "Epoch 76/300\n",
            "30/30 [==============================] - 0s 910us/step - loss: 0.8838 - accuracy: 0.5104\n",
            "Epoch 77/300\n",
            "30/30 [==============================] - 0s 915us/step - loss: 0.8804 - accuracy: 0.5104\n",
            "Epoch 78/300\n",
            "30/30 [==============================] - 0s 989us/step - loss: 0.8771 - accuracy: 0.5104\n",
            "Epoch 79/300\n",
            "30/30 [==============================] - 0s 994us/step - loss: 0.8740 - accuracy: 0.5104\n",
            "Epoch 80/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8706 - accuracy: 0.5104\n",
            "Epoch 81/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8676 - accuracy: 0.5104\n",
            "Epoch 82/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8644 - accuracy: 0.5104\n",
            "Epoch 83/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8614 - accuracy: 0.5083\n",
            "Epoch 84/300\n",
            "30/30 [==============================] - 0s 930us/step - loss: 0.8584 - accuracy: 0.5042\n",
            "Epoch 85/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8554 - accuracy: 0.5063\n",
            "Epoch 86/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8526 - accuracy: 0.5063\n",
            "Epoch 87/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8497 - accuracy: 0.5104\n",
            "Epoch 88/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8469 - accuracy: 0.5104\n",
            "Epoch 89/300\n",
            "30/30 [==============================] - 0s 948us/step - loss: 0.8442 - accuracy: 0.5063\n",
            "Epoch 90/300\n",
            "30/30 [==============================] - 0s 927us/step - loss: 0.8415 - accuracy: 0.5083\n",
            "Epoch 91/300\n",
            "30/30 [==============================] - 0s 977us/step - loss: 0.8390 - accuracy: 0.5104\n",
            "Epoch 92/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8363 - accuracy: 0.5125\n",
            "Epoch 93/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8337 - accuracy: 0.5167\n",
            "Epoch 94/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8313 - accuracy: 0.5167\n",
            "Epoch 95/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8287 - accuracy: 0.5188\n",
            "Epoch 96/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8263 - accuracy: 0.5208\n",
            "Epoch 97/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8242 - accuracy: 0.5271\n",
            "Epoch 98/300\n",
            "30/30 [==============================] - 0s 928us/step - loss: 0.8215 - accuracy: 0.5292\n",
            "Epoch 99/300\n",
            "30/30 [==============================] - 0s 964us/step - loss: 0.8193 - accuracy: 0.5312\n",
            "Epoch 100/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8170 - accuracy: 0.5333\n",
            "Epoch 101/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8146 - accuracy: 0.5333\n",
            "Epoch 102/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8125 - accuracy: 0.5396\n",
            "Epoch 103/300\n",
            "30/30 [==============================] - 0s 986us/step - loss: 0.8103 - accuracy: 0.5354\n",
            "Epoch 104/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8081 - accuracy: 0.5354\n",
            "Epoch 105/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8060 - accuracy: 0.5375\n",
            "Epoch 106/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8038 - accuracy: 0.5479\n",
            "Epoch 107/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.5604\n",
            "Epoch 108/300\n",
            "30/30 [==============================] - 0s 963us/step - loss: 0.8000 - accuracy: 0.5562\n",
            "Epoch 109/300\n",
            "30/30 [==============================] - 0s 929us/step - loss: 0.7980 - accuracy: 0.5521\n",
            "Epoch 110/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7959 - accuracy: 0.5562\n",
            "Epoch 111/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7940 - accuracy: 0.5542\n",
            "Epoch 112/300\n",
            "30/30 [==============================] - 0s 993us/step - loss: 0.7920 - accuracy: 0.5604\n",
            "Epoch 113/300\n",
            "30/30 [==============================] - 0s 975us/step - loss: 0.7901 - accuracy: 0.5625\n",
            "Epoch 114/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.7882 - accuracy: 0.5625\n",
            "Epoch 115/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7865 - accuracy: 0.5646\n",
            "Epoch 116/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7845 - accuracy: 0.5646\n",
            "Epoch 117/300\n",
            "30/30 [==============================] - 0s 937us/step - loss: 0.7829 - accuracy: 0.5625\n",
            "Epoch 118/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7810 - accuracy: 0.5667\n",
            "Epoch 119/300\n",
            "30/30 [==============================] - 0s 995us/step - loss: 0.7792 - accuracy: 0.5667\n",
            "Epoch 120/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7776 - accuracy: 0.5667\n",
            "Epoch 121/300\n",
            "30/30 [==============================] - 0s 971us/step - loss: 0.7759 - accuracy: 0.5688\n",
            "Epoch 122/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7742 - accuracy: 0.5667\n",
            "Epoch 123/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.5667\n",
            "Epoch 124/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7709 - accuracy: 0.5729\n",
            "Epoch 125/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7693 - accuracy: 0.5667\n",
            "Epoch 126/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7681 - accuracy: 0.5771\n",
            "Epoch 127/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7661 - accuracy: 0.5750\n",
            "Epoch 128/300\n",
            "30/30 [==============================] - 0s 985us/step - loss: 0.7646 - accuracy: 0.5708\n",
            "Epoch 129/300\n",
            "30/30 [==============================] - 0s 950us/step - loss: 0.7631 - accuracy: 0.5771\n",
            "Epoch 130/300\n",
            "30/30 [==============================] - 0s 930us/step - loss: 0.7616 - accuracy: 0.5750\n",
            "Epoch 131/300\n",
            "30/30 [==============================] - 0s 976us/step - loss: 0.7601 - accuracy: 0.5854\n",
            "Epoch 132/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.5792\n",
            "Epoch 133/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7570 - accuracy: 0.5833\n",
            "Epoch 134/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7557 - accuracy: 0.5896\n",
            "Epoch 135/300\n",
            "30/30 [==============================] - 0s 921us/step - loss: 0.7542 - accuracy: 0.5813\n",
            "Epoch 136/300\n",
            "30/30 [==============================] - 0s 959us/step - loss: 0.7528 - accuracy: 0.5813\n",
            "Epoch 137/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7515 - accuracy: 0.5792\n",
            "Epoch 138/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.5854\n",
            "Epoch 139/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7489 - accuracy: 0.5896\n",
            "Epoch 140/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.5917\n",
            "Epoch 141/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.5854\n",
            "Epoch 142/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.5917\n",
            "Epoch 143/300\n",
            "30/30 [==============================] - 0s 980us/step - loss: 0.7434 - accuracy: 0.5917\n",
            "Epoch 144/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.5938\n",
            "Epoch 145/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.5917\n",
            "Epoch 146/300\n",
            "30/30 [==============================] - 0s 957us/step - loss: 0.7397 - accuracy: 0.5917\n",
            "Epoch 147/300\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.7385 - accuracy: 0.5917\n",
            "Epoch 148/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.5917\n",
            "Epoch 149/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7360 - accuracy: 0.5938\n",
            "Epoch 150/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 0.5854\n",
            "Epoch 151/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.5917\n",
            "Epoch 152/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.5896\n",
            "Epoch 153/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.5875\n",
            "Epoch 154/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.5875\n",
            "Epoch 155/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7288 - accuracy: 0.5875\n",
            "Epoch 156/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.5896\n",
            "Epoch 157/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.5813\n",
            "Epoch 158/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.5875\n",
            "Epoch 159/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.5875\n",
            "Epoch 160/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.5833\n",
            "Epoch 161/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.5854\n",
            "Epoch 162/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.5875\n",
            "Epoch 163/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.5896\n",
            "Epoch 164/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7192 - accuracy: 0.5917\n",
            "Epoch 165/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.5896\n",
            "Epoch 166/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.5917\n",
            "Epoch 167/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.7161 - accuracy: 0.5938\n",
            "Epoch 168/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.5896\n",
            "Epoch 169/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.5917\n",
            "Epoch 170/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.5875\n",
            "Epoch 171/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.5917\n",
            "Epoch 172/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.5896\n",
            "Epoch 173/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.5896\n",
            "Epoch 174/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.5917\n",
            "Epoch 175/300\n",
            "30/30 [==============================] - 0s 991us/step - loss: 0.7086 - accuracy: 0.5917\n",
            "Epoch 176/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.5896\n",
            "Epoch 177/300\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.7067 - accuracy: 0.5938\n",
            "Epoch 178/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.5938\n",
            "Epoch 179/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.5979\n",
            "Epoch 180/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6000\n",
            "Epoch 181/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5938\n",
            "Epoch 182/300\n",
            "30/30 [==============================] - 0s 965us/step - loss: 0.7022 - accuracy: 0.5979\n",
            "Epoch 183/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6021\n",
            "Epoch 184/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7006 - accuracy: 0.5979\n",
            "Epoch 185/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5958\n",
            "Epoch 186/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5979\n",
            "Epoch 187/300\n",
            "30/30 [==============================] - 0s 995us/step - loss: 0.6980 - accuracy: 0.5958\n",
            "Epoch 188/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5938\n",
            "Epoch 189/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5917\n",
            "Epoch 190/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.6021\n",
            "Epoch 191/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5938\n",
            "Epoch 192/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5979\n",
            "Epoch 193/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5979\n",
            "Epoch 194/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5958\n",
            "Epoch 195/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5958\n",
            "Epoch 196/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5958\n",
            "Epoch 197/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5938\n",
            "Epoch 198/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.6000\n",
            "Epoch 199/300\n",
            "30/30 [==============================] - 0s 992us/step - loss: 0.6889 - accuracy: 0.5979\n",
            "Epoch 200/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5958\n",
            "Epoch 201/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5979\n",
            "Epoch 202/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5958\n",
            "Epoch 203/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5938\n",
            "Epoch 204/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5917\n",
            "Epoch 205/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5917\n",
            "Epoch 206/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5896\n",
            "Epoch 207/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5917\n",
            "Epoch 208/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5896\n",
            "Epoch 209/300\n",
            "30/30 [==============================] - 0s 985us/step - loss: 0.6817 - accuracy: 0.5979\n",
            "Epoch 210/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5729\n",
            "Epoch 211/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5917\n",
            "Epoch 212/300\n",
            "30/30 [==============================] - 0s 993us/step - loss: 0.6799 - accuracy: 0.6146\n",
            "Epoch 213/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.6167\n",
            "Epoch 214/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.6146\n",
            "Epoch 215/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.6125\n",
            "Epoch 216/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.6146\n",
            "Epoch 217/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.6146\n",
            "Epoch 218/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.6125\n",
            "Epoch 219/300\n",
            "30/30 [==============================] - 0s 975us/step - loss: 0.6753 - accuracy: 0.6125\n",
            "Epoch 220/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.6125\n",
            "Epoch 221/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.6125\n",
            "Epoch 222/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.6104\n",
            "Epoch 223/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.6125\n",
            "Epoch 224/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.6104\n",
            "Epoch 225/300\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.6718 - accuracy: 0.6125\n",
            "Epoch 226/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6146\n",
            "Epoch 227/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.6125\n",
            "Epoch 228/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.6125\n",
            "Epoch 229/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.6104\n",
            "Epoch 230/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.6104\n",
            "Epoch 231/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.6125\n",
            "Epoch 232/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6125\n",
            "Epoch 233/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6104\n",
            "Epoch 234/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6104\n",
            "Epoch 235/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6104\n",
            "Epoch 236/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6125\n",
            "Epoch 237/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6104\n",
            "Epoch 238/300\n",
            "30/30 [==============================] - 0s 985us/step - loss: 0.6648 - accuracy: 0.6125\n",
            "Epoch 239/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6125\n",
            "Epoch 240/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6125\n",
            "Epoch 241/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6167\n",
            "Epoch 242/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6125\n",
            "Epoch 243/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6187\n",
            "Epoch 244/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6125\n",
            "Epoch 245/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6146\n",
            "Epoch 246/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6167\n",
            "Epoch 247/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6167\n",
            "Epoch 248/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6167\n",
            "Epoch 249/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6167\n",
            "Epoch 250/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6167\n",
            "Epoch 251/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6146\n",
            "Epoch 252/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6187\n",
            "Epoch 253/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6167\n",
            "Epoch 254/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6167\n",
            "Epoch 255/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6187\n",
            "Epoch 256/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6208\n",
            "Epoch 257/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6167\n",
            "Epoch 258/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6187\n",
            "Epoch 259/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6187\n",
            "Epoch 260/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6167\n",
            "Epoch 261/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6187\n",
            "Epoch 262/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6187\n",
            "Epoch 263/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6187\n",
            "Epoch 264/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6146\n",
            "Epoch 265/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6167\n",
            "Epoch 266/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6167\n",
            "Epoch 267/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6167\n",
            "Epoch 268/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6146\n",
            "Epoch 269/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6167\n",
            "Epoch 270/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6146\n",
            "Epoch 271/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6167\n",
            "Epoch 272/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6167\n",
            "Epoch 273/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6167\n",
            "Epoch 274/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6187\n",
            "Epoch 275/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6187\n",
            "Epoch 276/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6167\n",
            "Epoch 277/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6167\n",
            "Epoch 278/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6167\n",
            "Epoch 279/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6187\n",
            "Epoch 280/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6167\n",
            "Epoch 281/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6167\n",
            "Epoch 282/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6146\n",
            "Epoch 283/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6187\n",
            "Epoch 284/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6167\n",
            "Epoch 285/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6167\n",
            "Epoch 286/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6187\n",
            "Epoch 287/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6167\n",
            "Epoch 288/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6146\n",
            "Epoch 289/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6167\n",
            "Epoch 290/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6125\n",
            "Epoch 291/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6421 - accuracy: 0.6187\n",
            "Epoch 292/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6167\n",
            "Epoch 293/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6167\n",
            "Epoch 294/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6104\n",
            "Epoch 295/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6167\n",
            "Epoch 296/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6167\n",
            "Epoch 297/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6187\n",
            "Epoch 298/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6146\n",
            "Epoch 299/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6146\n",
            "Epoch 300/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2166fa8550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pFIqlUfLeZ9",
        "outputId": "96c63fb9-f2ee-465f-b6e3-d4b9b4d90114"
      },
      "source": [
        "# testing first model:\n",
        "\n",
        "model.evaluate(\n",
        "  test_X,\n",
        "  new_test_y\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.5667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6641600131988525, 0.5666666626930237]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsDY_h7XS2vx",
        "outputId": "fa48dc85-ac24-4b51-e308-ba427106d7f5"
      },
      "source": [
        "# second control model described in the paper (one hidden layer 8 units):\n",
        "\n",
        "\n",
        "# making and training simple 1 hidden layer backprop network:\n",
        "\n",
        "# Build the model.\n",
        "model2 = Sequential([\n",
        "  Dense(8, activation='relu', input_shape=(480,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model2.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "model2.fit(\n",
        "  train_X,\n",
        "  new_train_y,\n",
        "  epochs=300,\n",
        "  batch_size=16,\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "30/30 [==============================] - 0s 947us/step - loss: 1.4132 - accuracy: 0.1396\n",
            "Epoch 2/300\n",
            "30/30 [==============================] - 0s 989us/step - loss: 1.4020 - accuracy: 0.1500\n",
            "Epoch 3/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.3933 - accuracy: 0.1375\n",
            "Epoch 4/300\n",
            "30/30 [==============================] - 0s 989us/step - loss: 1.3849 - accuracy: 0.1292\n",
            "Epoch 5/300\n",
            "30/30 [==============================] - 0s 920us/step - loss: 1.3760 - accuracy: 0.0833\n",
            "Epoch 6/300\n",
            "30/30 [==============================] - 0s 886us/step - loss: 1.3659 - accuracy: 0.1437\n",
            "Epoch 7/300\n",
            "30/30 [==============================] - 0s 917us/step - loss: 1.3542 - accuracy: 0.1979\n",
            "Epoch 8/300\n",
            "30/30 [==============================] - 0s 960us/step - loss: 1.3392 - accuracy: 0.2771\n",
            "Epoch 9/300\n",
            "30/30 [==============================] - 0s 908us/step - loss: 1.3232 - accuracy: 0.2750\n",
            "Epoch 10/300\n",
            "30/30 [==============================] - 0s 913us/step - loss: 1.3080 - accuracy: 0.2833\n",
            "Epoch 11/300\n",
            "30/30 [==============================] - 0s 992us/step - loss: 1.2924 - accuracy: 0.2979\n",
            "Epoch 12/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.2757 - accuracy: 0.4771\n",
            "Epoch 13/300\n",
            "30/30 [==============================] - 0s 965us/step - loss: 1.2584 - accuracy: 0.5271\n",
            "Epoch 14/300\n",
            "30/30 [==============================] - 0s 884us/step - loss: 1.2399 - accuracy: 0.5354\n",
            "Epoch 15/300\n",
            "30/30 [==============================] - 0s 901us/step - loss: 1.2206 - accuracy: 0.5375\n",
            "Epoch 16/300\n",
            "30/30 [==============================] - 0s 910us/step - loss: 1.2005 - accuracy: 0.5354\n",
            "Epoch 17/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1797 - accuracy: 0.5292\n",
            "Epoch 18/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1585 - accuracy: 0.5250\n",
            "Epoch 19/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1370 - accuracy: 0.5271\n",
            "Epoch 20/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.1150 - accuracy: 0.5250\n",
            "Epoch 21/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0927 - accuracy: 0.5271\n",
            "Epoch 22/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.0707 - accuracy: 0.5250\n",
            "Epoch 23/300\n",
            "30/30 [==============================] - 0s 964us/step - loss: 1.0489 - accuracy: 0.5250\n",
            "Epoch 24/300\n",
            "30/30 [==============================] - 0s 961us/step - loss: 1.0275 - accuracy: 0.5250\n",
            "Epoch 25/300\n",
            "30/30 [==============================] - 0s 961us/step - loss: 1.0067 - accuracy: 0.5250\n",
            "Epoch 26/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9870 - accuracy: 0.5354\n",
            "Epoch 27/300\n",
            "30/30 [==============================] - 0s 886us/step - loss: 0.9680 - accuracy: 0.5604\n",
            "Epoch 28/300\n",
            "30/30 [==============================] - 0s 912us/step - loss: 0.9497 - accuracy: 0.5667\n",
            "Epoch 29/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.9326 - accuracy: 0.5958\n",
            "Epoch 30/300\n",
            "30/30 [==============================] - 0s 932us/step - loss: 0.9167 - accuracy: 0.6375\n",
            "Epoch 31/300\n",
            "30/30 [==============================] - 0s 938us/step - loss: 0.9015 - accuracy: 0.6417\n",
            "Epoch 32/300\n",
            "30/30 [==============================] - 0s 977us/step - loss: 0.8874 - accuracy: 0.6417\n",
            "Epoch 33/300\n",
            "30/30 [==============================] - 0s 933us/step - loss: 0.8740 - accuracy: 0.6354\n",
            "Epoch 34/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8621 - accuracy: 0.6417\n",
            "Epoch 35/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8507 - accuracy: 0.6313\n",
            "Epoch 36/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8405 - accuracy: 0.6417\n",
            "Epoch 37/300\n",
            "30/30 [==============================] - 0s 947us/step - loss: 0.8306 - accuracy: 0.6208\n",
            "Epoch 38/300\n",
            "30/30 [==============================] - 0s 983us/step - loss: 0.8219 - accuracy: 0.6125\n",
            "Epoch 39/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8130 - accuracy: 0.6333\n",
            "Epoch 40/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.8050 - accuracy: 0.6313\n",
            "Epoch 41/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7979 - accuracy: 0.6292\n",
            "Epoch 42/300\n",
            "30/30 [==============================] - 0s 948us/step - loss: 0.7911 - accuracy: 0.6146\n",
            "Epoch 43/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7845 - accuracy: 0.6396\n",
            "Epoch 44/300\n",
            "30/30 [==============================] - 0s 985us/step - loss: 0.7785 - accuracy: 0.6562\n",
            "Epoch 45/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7727 - accuracy: 0.6542\n",
            "Epoch 46/300\n",
            "30/30 [==============================] - 0s 998us/step - loss: 0.7678 - accuracy: 0.6458\n",
            "Epoch 47/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7621 - accuracy: 0.6646\n",
            "Epoch 48/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7568 - accuracy: 0.6708\n",
            "Epoch 49/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7522 - accuracy: 0.6667\n",
            "Epoch 50/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6687\n",
            "Epoch 51/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6729\n",
            "Epoch 52/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6771\n",
            "Epoch 53/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6708\n",
            "Epoch 54/300\n",
            "30/30 [==============================] - 0s 918us/step - loss: 0.7306 - accuracy: 0.6833\n",
            "Epoch 55/300\n",
            "30/30 [==============================] - 0s 970us/step - loss: 0.7258 - accuracy: 0.6812\n",
            "Epoch 56/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.6750\n",
            "Epoch 57/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6750\n",
            "Epoch 58/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.6833\n",
            "Epoch 59/300\n",
            "30/30 [==============================] - 0s 997us/step - loss: 0.7102 - accuracy: 0.6771\n",
            "Epoch 60/300\n",
            "30/30 [==============================] - 0s 995us/step - loss: 0.7062 - accuracy: 0.6917\n",
            "Epoch 61/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.6812\n",
            "Epoch 62/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.7000\n",
            "Epoch 63/300\n",
            "30/30 [==============================] - 0s 920us/step - loss: 0.6949 - accuracy: 0.6917\n",
            "Epoch 64/300\n",
            "30/30 [==============================] - 0s 937us/step - loss: 0.6918 - accuracy: 0.6833\n",
            "Epoch 65/300\n",
            "30/30 [==============================] - 0s 974us/step - loss: 0.6881 - accuracy: 0.6792\n",
            "Epoch 66/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.6750\n",
            "Epoch 67/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.6812\n",
            "Epoch 68/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.6938\n",
            "Epoch 69/300\n",
            "30/30 [==============================] - 0s 964us/step - loss: 0.6752 - accuracy: 0.6792\n",
            "Epoch 70/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.6833\n",
            "Epoch 71/300\n",
            "30/30 [==============================] - 0s 988us/step - loss: 0.6691 - accuracy: 0.6729\n",
            "Epoch 72/300\n",
            "30/30 [==============================] - 0s 964us/step - loss: 0.6657 - accuracy: 0.6792\n",
            "Epoch 73/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6979\n",
            "Epoch 74/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6917\n",
            "Epoch 75/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6833\n",
            "Epoch 76/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6792\n",
            "Epoch 77/300\n",
            "30/30 [==============================] - 0s 969us/step - loss: 0.6519 - accuracy: 0.6833\n",
            "Epoch 78/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6979\n",
            "Epoch 79/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6896\n",
            "Epoch 80/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6812\n",
            "Epoch 81/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.6896\n",
            "Epoch 82/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6875\n",
            "Epoch 83/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6875\n",
            "Epoch 84/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.6979\n",
            "Epoch 85/300\n",
            "30/30 [==============================] - 0s 962us/step - loss: 0.6340 - accuracy: 0.6938\n",
            "Epoch 86/300\n",
            "30/30 [==============================] - 0s 945us/step - loss: 0.6322 - accuracy: 0.6979\n",
            "Epoch 87/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.6896\n",
            "Epoch 88/300\n",
            "30/30 [==============================] - 0s 978us/step - loss: 0.6275 - accuracy: 0.6896\n",
            "Epoch 89/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6979\n",
            "Epoch 90/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6958\n",
            "Epoch 91/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.7000\n",
            "Epoch 92/300\n",
            "30/30 [==============================] - 0s 962us/step - loss: 0.6219 - accuracy: 0.6979\n",
            "Epoch 93/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6875\n",
            "Epoch 94/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.7146\n",
            "Epoch 95/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.7125\n",
            "Epoch 96/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.6979\n",
            "Epoch 97/300\n",
            "30/30 [==============================] - 0s 989us/step - loss: 0.6127 - accuracy: 0.7083\n",
            "Epoch 98/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.7146\n",
            "Epoch 99/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.7104\n",
            "Epoch 100/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.7104\n",
            "Epoch 101/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.7104\n",
            "Epoch 102/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.7167\n",
            "Epoch 103/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.7125\n",
            "Epoch 104/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.7083\n",
            "Epoch 105/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.7167\n",
            "Epoch 106/300\n",
            "30/30 [==============================] - 0s 954us/step - loss: 0.5994 - accuracy: 0.7250\n",
            "Epoch 107/300\n",
            "30/30 [==============================] - 0s 942us/step - loss: 0.5979 - accuracy: 0.7188\n",
            "Epoch 108/300\n",
            "30/30 [==============================] - 0s 931us/step - loss: 0.5966 - accuracy: 0.7208\n",
            "Epoch 109/300\n",
            "30/30 [==============================] - 0s 927us/step - loss: 0.5951 - accuracy: 0.7229\n",
            "Epoch 110/300\n",
            "30/30 [==============================] - 0s 943us/step - loss: 0.5954 - accuracy: 0.7104\n",
            "Epoch 111/300\n",
            "30/30 [==============================] - 0s 976us/step - loss: 0.5931 - accuracy: 0.7292\n",
            "Epoch 112/300\n",
            "30/30 [==============================] - 0s 920us/step - loss: 0.5932 - accuracy: 0.7167\n",
            "Epoch 113/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.7208\n",
            "Epoch 114/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.7229\n",
            "Epoch 115/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.7125\n",
            "Epoch 116/300\n",
            "30/30 [==============================] - 0s 975us/step - loss: 0.5874 - accuracy: 0.7208\n",
            "Epoch 117/300\n",
            "30/30 [==============================] - 0s 963us/step - loss: 0.5860 - accuracy: 0.7271\n",
            "Epoch 118/300\n",
            "30/30 [==============================] - 0s 939us/step - loss: 0.5851 - accuracy: 0.7208\n",
            "Epoch 119/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7146\n",
            "Epoch 120/300\n",
            "30/30 [==============================] - 0s 929us/step - loss: 0.5840 - accuracy: 0.7229\n",
            "Epoch 121/300\n",
            "30/30 [==============================] - 0s 954us/step - loss: 0.5822 - accuracy: 0.7083\n",
            "Epoch 122/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7271\n",
            "Epoch 123/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7375\n",
            "Epoch 124/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7271\n",
            "Epoch 125/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7104\n",
            "Epoch 126/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7333\n",
            "Epoch 127/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7208\n",
            "Epoch 128/300\n",
            "30/30 [==============================] - 0s 918us/step - loss: 0.5746 - accuracy: 0.7333\n",
            "Epoch 129/300\n",
            "30/30 [==============================] - 0s 968us/step - loss: 0.5738 - accuracy: 0.7333\n",
            "Epoch 130/300\n",
            "30/30 [==============================] - 0s 975us/step - loss: 0.5732 - accuracy: 0.7271\n",
            "Epoch 131/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7250\n",
            "Epoch 132/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7312\n",
            "Epoch 133/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7354\n",
            "Epoch 134/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7292\n",
            "Epoch 135/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7250\n",
            "Epoch 136/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7312\n",
            "Epoch 137/300\n",
            "30/30 [==============================] - 0s 977us/step - loss: 0.5671 - accuracy: 0.7292\n",
            "Epoch 138/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7375\n",
            "Epoch 139/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7333\n",
            "Epoch 140/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7312\n",
            "Epoch 141/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7354\n",
            "Epoch 142/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7333\n",
            "Epoch 143/300\n",
            "30/30 [==============================] - 0s 982us/step - loss: 0.5622 - accuracy: 0.7271\n",
            "Epoch 144/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7292\n",
            "Epoch 145/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7417\n",
            "Epoch 146/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7333\n",
            "Epoch 147/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7292\n",
            "Epoch 148/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.7250\n",
            "Epoch 149/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7271\n",
            "Epoch 150/300\n",
            "30/30 [==============================] - 0s 965us/step - loss: 0.5577 - accuracy: 0.7417\n",
            "Epoch 151/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7271\n",
            "Epoch 152/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7333\n",
            "Epoch 153/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7354\n",
            "Epoch 154/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7417\n",
            "Epoch 155/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7500\n",
            "Epoch 156/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7417\n",
            "Epoch 157/300\n",
            "30/30 [==============================] - 0s 1000us/step - loss: 0.5528 - accuracy: 0.7229\n",
            "Epoch 158/300\n",
            "30/30 [==============================] - 0s 950us/step - loss: 0.5520 - accuracy: 0.7271\n",
            "Epoch 159/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7396\n",
            "Epoch 160/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7354\n",
            "Epoch 161/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7333\n",
            "Epoch 162/300\n",
            "30/30 [==============================] - 0s 972us/step - loss: 0.5493 - accuracy: 0.7375\n",
            "Epoch 163/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7333\n",
            "Epoch 164/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7458\n",
            "Epoch 165/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7479\n",
            "Epoch 166/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7458\n",
            "Epoch 167/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7354\n",
            "Epoch 168/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7437\n",
            "Epoch 169/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5450 - accuracy: 0.7417\n",
            "Epoch 170/300\n",
            "30/30 [==============================] - 0s 963us/step - loss: 0.5439 - accuracy: 0.7458\n",
            "Epoch 171/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7396\n",
            "Epoch 172/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7458\n",
            "Epoch 173/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7396\n",
            "Epoch 174/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7458\n",
            "Epoch 175/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.7396\n",
            "Epoch 176/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7500\n",
            "Epoch 177/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7479\n",
            "Epoch 178/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7396\n",
            "Epoch 179/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7375\n",
            "Epoch 180/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7396\n",
            "Epoch 181/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7500\n",
            "Epoch 182/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7479\n",
            "Epoch 183/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7437\n",
            "Epoch 184/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.7479\n",
            "Epoch 185/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7479\n",
            "Epoch 186/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7521\n",
            "Epoch 187/300\n",
            "30/30 [==============================] - 0s 990us/step - loss: 0.5356 - accuracy: 0.7396\n",
            "Epoch 188/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.7479\n",
            "Epoch 189/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7500\n",
            "Epoch 190/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7500\n",
            "Epoch 191/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7354\n",
            "Epoch 192/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7521\n",
            "Epoch 193/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7500\n",
            "Epoch 194/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7458\n",
            "Epoch 195/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7354\n",
            "Epoch 196/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7500\n",
            "Epoch 197/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7437\n",
            "Epoch 198/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7437\n",
            "Epoch 199/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7437\n",
            "Epoch 200/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7479\n",
            "Epoch 201/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7500\n",
            "Epoch 202/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7479\n",
            "Epoch 203/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7500\n",
            "Epoch 204/300\n",
            "30/30 [==============================] - 0s 997us/step - loss: 0.5279 - accuracy: 0.7458\n",
            "Epoch 205/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7500\n",
            "Epoch 206/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7500\n",
            "Epoch 207/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7479\n",
            "Epoch 208/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7479\n",
            "Epoch 209/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7521\n",
            "Epoch 210/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7479\n",
            "Epoch 211/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7521\n",
            "Epoch 212/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7479\n",
            "Epoch 213/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7563\n",
            "Epoch 214/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.7521\n",
            "Epoch 215/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7458\n",
            "Epoch 216/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7500\n",
            "Epoch 217/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7437\n",
            "Epoch 218/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7500\n",
            "Epoch 219/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7437\n",
            "Epoch 220/300\n",
            "30/30 [==============================] - 0s 988us/step - loss: 0.5213 - accuracy: 0.7542\n",
            "Epoch 221/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7500\n",
            "Epoch 222/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7521\n",
            "Epoch 223/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7458\n",
            "Epoch 224/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7583\n",
            "Epoch 225/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7563\n",
            "Epoch 226/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.7521\n",
            "Epoch 227/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7500\n",
            "Epoch 228/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7542\n",
            "Epoch 229/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7458\n",
            "Epoch 230/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7563\n",
            "Epoch 231/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7521\n",
            "Epoch 232/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7521\n",
            "Epoch 233/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7479\n",
            "Epoch 234/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7479\n",
            "Epoch 235/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7521\n",
            "Epoch 236/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7479\n",
            "Epoch 237/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7521\n",
            "Epoch 238/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7479\n",
            "Epoch 239/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7521\n",
            "Epoch 240/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7521\n",
            "Epoch 241/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7542\n",
            "Epoch 242/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7542\n",
            "Epoch 243/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7500\n",
            "Epoch 244/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7542\n",
            "Epoch 245/300\n",
            "30/30 [==============================] - 0s 967us/step - loss: 0.5133 - accuracy: 0.7521\n",
            "Epoch 246/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7500\n",
            "Epoch 247/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7542\n",
            "Epoch 248/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7479\n",
            "Epoch 249/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7500\n",
            "Epoch 250/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7583\n",
            "Epoch 251/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7521\n",
            "Epoch 252/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7542\n",
            "Epoch 253/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7458\n",
            "Epoch 254/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7479\n",
            "Epoch 255/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7583\n",
            "Epoch 256/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7500\n",
            "Epoch 257/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7458\n",
            "Epoch 258/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7500\n",
            "Epoch 259/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7563\n",
            "Epoch 260/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7542\n",
            "Epoch 261/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7563\n",
            "Epoch 262/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7563\n",
            "Epoch 263/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7500\n",
            "Epoch 264/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7458\n",
            "Epoch 265/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7542\n",
            "Epoch 266/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7563\n",
            "Epoch 267/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7437\n",
            "Epoch 268/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7563\n",
            "Epoch 269/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7563\n",
            "Epoch 270/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7521\n",
            "Epoch 271/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7479\n",
            "Epoch 272/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7521\n",
            "Epoch 273/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7521\n",
            "Epoch 274/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7521\n",
            "Epoch 275/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7479\n",
            "Epoch 276/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7521\n",
            "Epoch 277/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7458\n",
            "Epoch 278/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7500\n",
            "Epoch 279/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7521\n",
            "Epoch 280/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7458\n",
            "Epoch 281/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7458\n",
            "Epoch 282/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7563\n",
            "Epoch 283/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7563\n",
            "Epoch 284/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7521\n",
            "Epoch 285/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7542\n",
            "Epoch 286/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7563\n",
            "Epoch 287/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7521\n",
            "Epoch 288/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7417\n",
            "Epoch 289/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7542\n",
            "Epoch 290/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7583\n",
            "Epoch 291/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7458\n",
            "Epoch 292/300\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7521\n",
            "Epoch 293/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7563\n",
            "Epoch 294/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7500\n",
            "Epoch 295/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7563\n",
            "Epoch 296/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7542\n",
            "Epoch 297/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7563\n",
            "Epoch 298/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7583\n",
            "Epoch 299/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7563\n",
            "Epoch 300/300\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2164662780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW88czz_Tqhp",
        "outputId": "3d7a2587-bfcb-41f0-fb0f-8234d883aa3a"
      },
      "source": [
        "# testing second model:\n",
        "\n",
        "model2.evaluate(\n",
        "  test_X,\n",
        "  new_test_y\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.6917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5590284466743469, 0.6916666626930237]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXlp1qvuVM_z",
        "outputId": "5bbf1a4d-b2dd-4358-ffbf-47e6076973bf"
      },
      "source": [
        "new_test_y[0:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGcMYvtMT6We",
        "outputId": "ad4ad688-2448-4587-d205-a256b749e75d"
      },
      "source": [
        "# just visually comparing expected to results:\n",
        "\n",
        "predictions = model2.predict(test_X)\n",
        "\n",
        "# iterate through results, convert largest in each sample to 1 and smallest to 0\n",
        "\n",
        "# convert predictions and the samples inside it from np to list so we can use index fxn:\n",
        "predictions2 = list(predictions)\n",
        "for i in range(len(predictions2)):\n",
        "  predictions2[i] = list(predictions2[i])\n",
        "\n",
        "\n",
        "for sample in predictions2:\n",
        "  # change max predicted value to 1 as sigmoid is returning prob, so highest prob is 1\n",
        "  sample[(sample.index(max(sample)))] = 1\n",
        "\n",
        "for i in range(len(predictions2)):\n",
        "  for j in range(len(sample)):\n",
        "    if predictions2[i][j] != 1:\n",
        "      predictions2[i][j] = 0\n",
        "\n",
        "\n",
        "predictions2[0:10]\n",
        "# compare these predictions to actual in previous cell"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 480, 2) for input Tensor(\"dense_2_input:0\", shape=(None, 480, 2), dtype=float32), but it was called on an input with incompatible shape (None, 2).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1],\n",
              " [0, 0, 0, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3l00uZXAsWz"
      },
      "source": [
        "## **PROBABILITY MODEL BELOW:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSAQlWsC3tpo",
        "outputId": "8093a2f0-e1ee-476d-9084-af5dd4f9397f"
      },
      "source": [
        "# supress tensorflow warnings:\n",
        "import os\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "\n",
        "# matrix of probabilities to be updated:\n",
        "prob_matrix = {'p_ex_1_a': 0.5,'p_ex_1_A': 0.5,'p_ex_1_i': 0.5,'p_ex_1_I': 0.5,\n",
        "               'p_ex_2_a': 0.5,'p_ex_2_A': 0.5,'p_ex_2_i': 0.5,'p_ex_2_I': 0.5,\n",
        "               'p_ex_3_a': 0.5,'p_ex_3_A': 0.5,'p_ex_3_i': 0.5,'p_ex_3_I': 0.5,\n",
        "               'p_ex_4_a': 0.5,'p_ex_4_A': 0.5,'p_ex_4_i': 0.5,'p_ex_4_I': 0.5}\n",
        "\n",
        "# probability change function:\n",
        "def prob_change(p, E_avg, target, y_i):\n",
        "  d_p = p*((E_avg**2)-(target-y_i)**2)\n",
        "  return d_p\n",
        "\n",
        "prob_matrix"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'p_ex_1_A': 0.5,\n",
              " 'p_ex_1_I': 0.5,\n",
              " 'p_ex_1_a': 0.5,\n",
              " 'p_ex_1_i': 0.5,\n",
              " 'p_ex_2_A': 0.5,\n",
              " 'p_ex_2_I': 0.5,\n",
              " 'p_ex_2_a': 0.5,\n",
              " 'p_ex_2_i': 0.5,\n",
              " 'p_ex_3_A': 0.5,\n",
              " 'p_ex_3_I': 0.5,\n",
              " 'p_ex_3_a': 0.5,\n",
              " 'p_ex_3_i': 0.5,\n",
              " 'p_ex_4_A': 0.5,\n",
              " 'p_ex_4_I': 0.5,\n",
              " 'p_ex_4_a': 0.5,\n",
              " 'p_ex_4_i': 0.5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5TkX6kNAlII"
      },
      "source": [
        "\n",
        "# define the expert model architectures:\n",
        "  # define the models to only take one sampmle at a time:\n",
        "expert_1 = Sequential([\n",
        "  Dense(8, activation='relu', input_shape=(1,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "expert_2 = Sequential([\n",
        "  Dense(8, activation='relu', input_shape=(1,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "expert_3 = Sequential([\n",
        "  Dense(8, activation='relu', input_shape=(1,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "expert_4 = Sequential([\n",
        "  Dense(8, activation='relu', input_shape=(1,2)),\n",
        "  Dense(4, activation='sigmoid'),\n",
        "])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K4--xBTVAnYu",
        "outputId": "16200431-0ad1-4e76-8779-a4035740fa96"
      },
      "source": [
        "# split up training data into one-sample slices:\n",
        "# loop through training data:\n",
        "\n",
        "num_epochs = 1 \n",
        "\n",
        "# outer loop determines how many times to run over entire dataset:\n",
        "for j in range(num_epochs):\n",
        "  # inner loop iterates over each sample:\n",
        "  for i in range(len(train_X)):\n",
        "    \n",
        "\n",
        "  ## EXPERT 1:\n",
        "    # compile model:\n",
        "    expert_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "    # learning rate reset every time compiles if not on first sample:\n",
        "    # change learning rates to match probs in matrix:\n",
        "    if i !=0:\n",
        "      # don't change for first iteration\n",
        "      # change class \"a\" learning rates to match probs in matrix:\n",
        "      if new_train_y[i][0] == 1:\n",
        "        expert_1.optimizer.lr = past_learning_rate_ex_1+prob_matrix['p_ex_1_a']\n",
        "        expert_2.optimizer.lr = past_learning_rate_ex_2+prob_matrix['p_ex_2_a']\n",
        "        expert_3.optimizer.lr = past_learning_rate_ex_3+prob_matrix['p_ex_3_a']\n",
        "        expert_4.optimizer.lr = past_learning_rate_ex_4+prob_matrix['p_ex_4_a']\n",
        "\n",
        "      # change class \"A\" learning rates to match probs in matrix:\n",
        "      if new_train_y[i][1] == 1:\n",
        "        expert_1.optimizer.lr = past_learning_rate_ex_1+prob_matrix['p_ex_1_A']\n",
        "        expert_2.optimizer.lr = past_learning_rate_ex_2+prob_matrix['p_ex_2_A']\n",
        "        expert_3.optimizer.lr = past_learning_rate_ex_3+prob_matrix['p_ex_3_A']\n",
        "        expert_4.optimizer.lr = past_learning_rate_ex_4+prob_matrix['p_ex_4_A']\n",
        "\n",
        "      # change class \"i\" learning rates to match probs in matrix:\n",
        "      if new_train_y[i][2] == 1:\n",
        "        expert_1.optimizer.lr = past_learning_rate_ex_1+prob_matrix['p_ex_1_i']\n",
        "        expert_2.optimizer.lr = past_learning_rate_ex_2+prob_matrix['p_ex_2_i']\n",
        "        expert_3.optimizer.lr = past_learning_rate_ex_3+prob_matrix['p_ex_3_i']\n",
        "        expert_4.optimizer.lr = past_learning_rate_ex_4+prob_matrix['p_ex_4_i']\n",
        "\n",
        "      # change class \"I\" learning rates to match probs in matrix:\n",
        "      if new_train_y[i][3] == 1:\n",
        "        expert_1.optimizer.lr = past_learning_rate_ex_1+prob_matrix['p_ex_1_I']\n",
        "        expert_2.optimizer.lr = past_learning_rate_ex_2+prob_matrix['p_ex_2_I']\n",
        "        expert_3.optimizer.lr = past_learning_rate_ex_3+prob_matrix['p_ex_3_I']\n",
        "        expert_4.optimizer.lr = past_learning_rate_ex_4+prob_matrix['p_ex_4_I']\n",
        "\n",
        "    # need to format training data like this for keras to acccept sample shape:\n",
        "    print('training expert_1')\n",
        "    print('\\n')\n",
        "    expert_1_history = expert_1.fit(\n",
        "      np.array([train_X[i]]),\n",
        "      np.array([new_train_y[i]]),\n",
        "      epochs=1,\n",
        "      batch_size=128,\n",
        "    )\n",
        "\n",
        "    ex_1_pred = expert_1.predict(np.array([train_X[i]]))\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  ## EXPERT 2:\n",
        "      # compile model:\n",
        "    expert_2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "    print('training expert_2')\n",
        "    print('\\n')\n",
        "    # Train the model.\n",
        "    expert_2_history = expert_2.fit(\n",
        "      np.array([train_X[i]]),\n",
        "      np.array([new_train_y[i]]),\n",
        "      epochs=1,\n",
        "      batch_size=128,\n",
        "    )\n",
        "\n",
        "    ex_2_pred = expert_2.predict(np.array([train_X[i]]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ## EXPERT 3:\n",
        "      # compile model:\n",
        "    expert_3.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "    # Train the model.\n",
        "    print('training expert_3')\n",
        "    print('\\n')\n",
        "    expert_3_history = expert_3.fit(\n",
        "      np.array([train_X[i]]),\n",
        "      np.array([new_train_y[i]]),\n",
        "      epochs=1,\n",
        "      batch_size=128,\n",
        "    )\n",
        "\n",
        "    ex_3_pred = expert_3.predict(np.array([train_X[i]]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ## EXPERT 4:\n",
        "      # compile model:\n",
        "    expert_4.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "    # Train the model.\n",
        "    print('training expert_4')\n",
        "    print('\\n')\n",
        "    expert_4_history = expert_4.fit(\n",
        "    np.array([train_X[i]]),\n",
        "    np.array([new_train_y[i]]),\n",
        "      epochs=1,\n",
        "      batch_size=128,\n",
        "    )\n",
        "\n",
        "    ex_4_pred = expert_4.predict(np.array([train_X[i]]))\n",
        "\n",
        "    # save current learning rate for next iteration for all experts:\n",
        "    past_learning_rate_ex_1 = expert_1.optimizer.lr\n",
        "    past_learning_rate_ex_2 = expert_2.optimizer.lr\n",
        "    past_learning_rate_ex_3 = expert_3.optimizer.lr\n",
        "    past_learning_rate_ex_4 = expert_4.optimizer.lr\n",
        "\n",
        "\n",
        "    # \"a\" CLASS WEIGHT UPDATES:\n",
        "    if new_train_y[i][0] == 1:\n",
        "\n",
        "      ex_1_error_sq = (new_train_y[i][0]-ex_1_pred[0][0])**2\n",
        "      ex_2_error_sq = (new_train_y[i][0]-ex_2_pred[0][0])**2\n",
        "      ex_3_error_sq = (new_train_y[i][0]-ex_3_pred[0][0])**2\n",
        "      ex_4_error_sq = (new_train_y[i][0]-ex_4_pred[0][0])**2\n",
        "\n",
        "      # average error\n",
        "      E_avg = (ex_1_error_sq + ex_2_error_sq + ex_3_error_sq + ex_4_error_sq)/4\n",
        "\n",
        "      prob_matrix['p_ex_1_a'] = prob_matrix['p_ex_1_a'] + prob_change(prob_matrix['p_ex_1_a'], E_avg, new_train_y[i][0], ex_1_pred[0][0])\n",
        "      prob_matrix['p_ex_2_a'] = prob_matrix['p_ex_2_a'] + prob_change(prob_matrix['p_ex_2_a'], E_avg, new_train_y[i][0], ex_2_pred[0][0])\n",
        "      prob_matrix['p_ex_3_a'] = prob_matrix['p_ex_3_a'] + prob_change(prob_matrix['p_ex_3_a'], E_avg, new_train_y[i][0], ex_3_pred[0][0])\n",
        "      prob_matrix['p_ex_4_a'] = prob_matrix['p_ex_4_a'] + prob_change(prob_matrix['p_ex_4_a'], E_avg, new_train_y[i][0], ex_4_pred[0][0])\n",
        "      # this update function sucks but it runs!!! so let's go\n",
        "\n",
        "\n",
        "    # \"A\" CLASS PROBABILITY UPDATES:\n",
        "    elif new_train_y[i][1] == 1:\n",
        "\n",
        "      ex_1_error_sq = (new_train_y[i][1]-ex_1_pred[0][1])**2\n",
        "      ex_2_error_sq = (new_train_y[i][1]-ex_2_pred[0][1])**2\n",
        "      ex_3_error_sq = (new_train_y[i][1]-ex_3_pred[0][1])**2\n",
        "      ex_4_error_sq = (new_train_y[i][1]-ex_4_pred[0][1])**2\n",
        "\n",
        "      # average error\n",
        "      E_avg = (ex_1_error_sq + ex_2_error_sq + ex_3_error_sq + ex_4_error_sq)/4\n",
        "      prob_matrix['p_ex_1_A'] = prob_matrix['p_ex_1_A'] + prob_change(prob_matrix['p_ex_1_A'], E_avg, new_train_y[i][1], ex_1_pred[0][1])\n",
        "      prob_matrix['p_ex_2_A'] = prob_matrix['p_ex_2_A'] + prob_change(prob_matrix['p_ex_2_A'], E_avg, new_train_y[i][1], ex_2_pred[0][1])\n",
        "      prob_matrix['p_ex_3_A'] = prob_matrix['p_ex_3_A'] + prob_change(prob_matrix['p_ex_3_A'], E_avg, new_train_y[i][1], ex_3_pred[0][1])\n",
        "      prob_matrix['p_ex_4_A'] = prob_matrix['p_ex_4_A'] + prob_change(prob_matrix['p_ex_4_A'], E_avg, new_train_y[i][1], ex_4_pred[0][1])\n",
        "\n",
        "    # \"i\" CLASS PROBABILITY UPDATES:\n",
        "    elif new_train_y[i][2] == 1:\n",
        "\n",
        "      ex_1_error_sq = (new_train_y[i][2]-ex_1_pred[0][2])**2\n",
        "      ex_2_error_sq = (new_train_y[i][2]-ex_2_pred[0][2])**2\n",
        "      ex_3_error_sq = (new_train_y[i][2]-ex_3_pred[0][2])**2\n",
        "      ex_4_error_sq = (new_train_y[i][2]-ex_4_pred[0][2])**2\n",
        "\n",
        "      # average error\n",
        "      E_avg = (ex_1_error_sq + ex_2_error_sq + ex_3_error_sq + ex_4_error_sq)/4\n",
        "      prob_matrix['p_ex_1_i'] = prob_matrix['p_ex_1_i'] + prob_change(prob_matrix['p_ex_1_i'], E_avg, new_train_y[i][2], ex_1_pred[0][2])\n",
        "      prob_matrix['p_ex_2_i'] = prob_matrix['p_ex_2_i'] + prob_change(prob_matrix['p_ex_2_i'], E_avg, new_train_y[i][2], ex_2_pred[0][2])\n",
        "      prob_matrix['p_ex_3_i'] = prob_matrix['p_ex_3_i'] + prob_change(prob_matrix['p_ex_3_i'], E_avg, new_train_y[i][2], ex_3_pred[0][2])\n",
        "      prob_matrix['p_ex_4_i'] = prob_matrix['p_ex_4_i'] + prob_change(prob_matrix['p_ex_4_i'], E_avg, new_train_y[i][2], ex_4_pred[0][2])\n",
        "\n",
        "\n",
        "    # \"I\" CLASS PROBABILITY UPDATES:\n",
        "    elif new_train_y[i][3] == 1:\n",
        "\n",
        "      ex_1_error_sq = (new_train_y[i][2]-ex_1_pred[0][3])**2\n",
        "      ex_2_error_sq = (new_train_y[i][2]-ex_2_pred[0][3])**2\n",
        "      ex_3_error_sq = (new_train_y[i][2]-ex_3_pred[0][3])**2\n",
        "      ex_4_error_sq = (new_train_y[i][2]-ex_4_pred[0][3])**2\n",
        "\n",
        "      prob_matrix['p_ex_1_I'] = prob_matrix['p_ex_1_I'] + prob_change(prob_matrix['p_ex_1_I'], E_avg, new_train_y[i][3], ex_1_pred[0][3])\n",
        "      prob_matrix['p_ex_2_I'] = prob_matrix['p_ex_2_I'] + prob_change(prob_matrix['p_ex_2_I'], E_avg, new_train_y[i][3], ex_2_pred[0][3])\n",
        "      prob_matrix['p_ex_3_I'] = prob_matrix['p_ex_3_I'] + prob_change(prob_matrix['p_ex_3_I'], E_avg, new_train_y[i][3], ex_3_pred[0][3])\n",
        "      prob_matrix['p_ex_4_I'] = prob_matrix['p_ex_4_I'] + prob_change(prob_matrix['p_ex_4_I'], E_avg, new_train_y[i][3], ex_4_pred[0][3])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training expert_1\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6467 - accuracy: 0.0000e+00\n",
            "training expert_2\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7334 - accuracy: 0.0000e+00\n",
            "training expert_3\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8569 - accuracy: 1.0000\n",
            "training expert_4\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3561 - accuracy: 0.0000e+00\n",
            "training expert_1\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1424 - accuracy: 1.0000\n",
            "training expert_2\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6475 - accuracy: 0.0000e+00\n",
            "training expert_3\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8035 - accuracy: 0.0000e+00\n",
            "training expert_4\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3719 - accuracy: 0.0000e+00\n",
            "training expert_1\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2431 - accuracy: 0.0000e+00\n",
            "training expert_2\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3144 - accuracy: 0.0000e+00\n",
            "training expert_3\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1852 - accuracy: 1.0000\n",
            "training expert_4\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4863 - accuracy: 0.0000e+00\n",
            "training expert_1\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 1.0000\n",
            "training expert_2\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2763 - accuracy: 0.0000e+00\n",
            "training expert_3\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0925 - accuracy: 1.0000\n",
            "training expert_4\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5201 - accuracy: 0.0000e+00\n",
            "training expert_1\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 15.4815 - accuracy: 0.0000e+00\n",
            "training expert_2\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7319 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-03865bed07ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mex_2_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m                 ))\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    518\u001b[0m   if any(\n\u001b[1;32m    519\u001b[0m       \u001b[0m_is_of_known_loaded_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m       for m in ('collections', 'pdb', 'copy', 'inspect', 're')):\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently whitelisted: %s: part of builtin module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m   if any(\n\u001b[1;32m    519\u001b[0m       \u001b[0m_is_of_known_loaded_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m       for m in ('collections', 'pdb', 'copy', 'inspect', 're')):\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently whitelisted: %s: part of builtin module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_is_of_known_loaded_module\u001b[0;34m(f, module_name)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVH-8E-8zrhd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}